{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a147026d-92ec-4ea4-9186-b40da436443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 14:05:11.362828: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-10 14:05:13.773352: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-10 14:05:13.773802: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-10 14:05:14.092966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-10 14:05:15.007359: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-10 14:05:29.092765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando novos neurônios!\n",
      "Criando novos neurônios!\n",
      "Criando novos neurônios!\n",
      "Criando novos neurônios!\n",
      "Criando novos neurônios!\n",
      "7/7 [==============================] - 0s 11ms/step\n",
      "7/7 [==============================] - 0s 14ms/step\n",
      "Erro Quadrático Médio: 0.07538006754752988\n",
      "Coeficiente de Determinação: 0.9240910166457702\n",
      "[[40. 48. 10. 18. 25. 34.]\n",
      " [42. 48. 12. 19. 26. 34.]\n",
      " [42. 48. 14. 20. 27. 35.]\n",
      " [43. 48. 16. 21. 27. 35.]\n",
      " [43. 48. 17. 22. 28. 36.]\n",
      " [43. 47. 19. 23. 29. 36.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, GRU\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "class NeurogenesisLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_neurons):\n",
    "        super(NeurogenesisLayer, self).__init__()\n",
    "        self.num_neurons = num_neurons\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(NeurogenesisLayer, self).build(input_shape)\n",
    "        self.neurons = tf.keras.layers.Dense(self.num_neurons)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        new_neurons = self.neurons(inputs)\n",
    "        print(\"Criando novos neurônios!\")\n",
    "        neurons = tf.concat([inputs, new_neurons], axis=1)\n",
    "        return neurons\n",
    "\n",
    "\n",
    "def perda_penalidade_repeticao(y_true, y_pred):\n",
    "    diff = y_pred[:, 1:] - y_pred[:, :-1]\n",
    "    penalidade = K.sum(K.square(diff))\n",
    "    perda_mse = K.mean(K.square(y_true - y_pred))\n",
    "    perda_total = perda_mse + penalidade\n",
    "\n",
    "    return perda_total\n",
    "\n",
    "def perda_personalizada(y_true, y_pred):\n",
    "    limite_superior = 2.0\n",
    "    perda_penalizacao = K.mean(K.maximum(y_pred - limite_superior, 0))\n",
    "    return perda_penalizacao\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/cardosource/OraculoAI/main/atualizado.csv', header=None)\n",
    "\n",
    "\n",
    "data = np.array(df).reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "#LSTM model\n",
    "lookback = 6\n",
    "X = []\n",
    "y = []\n",
    "for i in range(lookback, len(data)):\n",
    "    X.append(data_scaled[i-lookback:i, 0])\n",
    "    y.append(data_scaled[i, 0])\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "train_size = int(len(X) * 0.7)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(GRU(50, activation='relu', input_shape=(lookback, 1)))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(NeurogenesisLayer(11))  # Adicione a camada de neurogênese com 10 novos neurônios\n",
    "model_lstm.add(Dense(1))\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "model_lstm.compile(loss=perda_personalizada, optimizer='adam')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.0001)\n",
    "\n",
    "# Treino LSTM model\n",
    "model_lstm.fit(X_train.reshape((X_train.shape[0], X_train.shape[1], 1)),\n",
    "               y_train,\n",
    "               epochs=200,\n",
    "               verbose=0,\n",
    "               callbacks=[reduce_lr],\n",
    "               validation_data=(X_test.reshape((X_test.shape[0], X_test.shape[1], 1)), y_test))\n",
    "\n",
    "\n",
    "forecast_lstm = []\n",
    "current_lstm = X_test[-1]\n",
    "for i in range(36):\n",
    "    x_input = np.reshape(current_lstm, (1, lookback, 1))\n",
    "    yhat = model_lstm.predict(x_input, verbose=0)\n",
    "    forecast_lstm.append(yhat[0])\n",
    "    current_lstm = np.append(current_lstm[1:], yhat[0])\n",
    "forecast_lstm = scaler.inverse_transform(np.array(forecast_lstm).reshape(-1, 1))\n",
    "\n",
    "\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(GRU(50, activation='relu', input_shape=(lookback, 1)))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(1))\n",
    "model1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(GRU(100, activation='relu', input_shape=(lookback, 1)))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model1.fit(X_train.reshape((X_train.shape[0], X_train.shape[1], 1)), y_train, epochs=100, verbose=0)\n",
    "model2.fit(X_train.reshape((X_train.shape[0], X_train.shape[1], 1)), y_train, epochs=100, verbose=0)\n",
    "\n",
    "\n",
    "forecast_ensemble = []\n",
    "current_ensemble = X_test[-1]\n",
    "for i in range(36):\n",
    "    x_input = np.reshape(current_ensemble, (1, lookback, 1))\n",
    "    yhat1 = model1.predict(x_input, verbose=0)\n",
    "    yhat2 = model2.predict(x_input, verbose=0)\n",
    "    yhat_ensemble = np.mean([yhat1[0], yhat2[0]])  # Combine predictions with mean\n",
    "    forecast_ensemble.append(yhat_ensemble)\n",
    "    current_ensemble = np.append(current_ensemble[1:], yhat_ensemble)\n",
    "forecast_ensemble = scaler.inverse_transform(np.array(forecast_ensemble).reshape(-1, 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ensemble_predictions = np.mean([model1.predict(X_test.reshape((X_test.shape[0], X_test.shape[1], 1))),\n",
    "                               model2.predict(X_test.reshape((X_test.shape[0], X_test.shape[1], 1)))]\n",
    "                               , axis=0)\n",
    "mse_ensemble = mean_squared_error(y_test, ensemble_predictions.flatten())  #converter  a matriz multidimensional para um vetor unidimensional\n",
    "r2_ensemble = r2_score(y_test, ensemble_predictions.flatten())   \n",
    "print('Erro Quadrático Médio:', mse_ensemble)\n",
    "print('Coeficiente de Determinação:', r2_ensemble)\n",
    "\n",
    "forecast_ensemble = forecast_ensemble.flatten()\n",
    "forecast_ensemble = forecast_ensemble.reshape(-1, 6)   \n",
    "forecast_ensemble = np.round(forecast_ensemble, 0)\n",
    "\n",
    "print(forecast_ensemble)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69581dec-cfc2-44f7-9bd0-cd7edc0bedb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
